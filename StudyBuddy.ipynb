{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "0f0299c6-e88f-4597-853c-5fbedfb9fcf2",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_absolute_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nimport joblib\n\ndf = pd.read_csv(\"student_exam_data.csv\")\nprint(\"Dataset loaded successfully!\")\nprint(df.head())\n\nTARGET = \"Study Hours\"     \n\nif TARGET not in df.columns:\n    raise ValueError(f\"Target column '{TARGET}' not found. Please check dataset columns.\")\n\n\nX = df.drop(columns=[TARGET])\ny = df[TARGET]\n\n\nnumeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_features = X.select_dtypes(include=['object']).columns.tolist()\n\nprint(\"Numeric columns:\", numeric_features)\nprint(\"Categorical columns:\", categorical_features)\n\n\nnumeric_transformer = StandardScaler()\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_features),\n        (\"cat\", categorical_transformer, categorical_features)\n    ]\n)\n\n\nmodel = RandomForestRegressor(\n    n_estimators=300,\n    max_depth=10,\n    random_state=42\n)\n\npipeline = Pipeline(steps=[\n    (\"preprocessor\", preprocessor),\n    (\"model\", model)\n])\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\npipeline.fit(X_train, y_train)\nprint(\"Model training completed!\")\n\npreds = pipeline.predict(X_test)\n\nmae = mean_absolute_error(y_test, preds)\nr2 = r2_score(y_test, preds)\n\nprint(f\"MAE: {mae:.3f}\")\nprint(f\"R² Score: {r2:.3f}\")\n\nimport warnings\nfrom pandas.api.types import is_numeric_dtype\n\npreproc = pipeline.named_steps[\"preprocessor\"]\nrf = pipeline.named_steps[\"model\"]\n\n\ntry:\n    numeric_features = list(preproc.transformers_[0][2])  \nexcept Exception:\n \n    numeric_features = [c for c in X.columns if is_numeric_dtype(X[c])]\n\ncat_feature_names = []\ntry:\n\n    cat_transformer = preproc.named_transformers_.get(\"cat\")\n    if cat_transformer is not None:\n\n        try:\n            cat_feature_names = cat_transformer.get_feature_names_out(categorical_features)\n        except Exception:\n            \n            try:\n                cat_feature_names = cat_transformer.get_feature_names(categorical_features)\n            except Exception:\n              \n                cat_feature_names = []\n    else:\n        cat_feature_names = []\nexcept Exception:\n    cat_feature_names = []\n    \n\nif isinstance(cat_feature_names, np.ndarray):\n    cat_feature_names = cat_feature_names.tolist()\n\nall_features = list(numeric_features) + list(cat_feature_names)\n\nimportances = None\nif hasattr(rf, \"feature_importances_\"):\n    importances = rf.feature_importances_\nelse:\n    warnings.warn(\"Model does not expose feature_importances_. Skipping importance extraction.\")\n\nif importances is None:\n    print(\"No importances to show.\")\nelse:\n    if len(importances) != len(all_features):\n\n        sample = X_train.iloc[:5].copy()\n        transformed = preproc.transform(sample)\n        transformed_dim = transformed.shape[1]\n        if transformed_dim == len(importances):\n     \n            if len(all_features) != transformed_dim:\n                all_features = [f\"f{i}\" for i in range(transformed_dim)]\n        else:\n  \n            warnings.warn(\n                f\"Feature count mismatch: {len(all_features)} names vs {len(importances)} importances.\\n\"\n                \"Will display first min(len) pairs.\"\n            )\n    \n    min_len = min(len(all_features), len(importances))\n    feat_df = pd.DataFrame({\n        \"feature\": all_features[:min_len],\n        \"importance\": importances[:min_len]\n    }).sort_values(\"importance\", ascending=False)\n    \n    print(\"\\nTop important features (showing up to first 50):\")\n    print(feat_df.head(50))\n\ndef study_plan(score):\n    \"\"\"\n    Generates a simple study recommendation based on predicted score.\n    Adjust thresholds to match your dataset.\n    \"\"\"\n\n    if score < 40:\n        return (\n            \"Your performance is low.\\n\"\n            \"- Study 3–4 hours per day\\n\"\n            \"- Focus first on weak subjects\\n\"\n            \"- Solve at least 30 practice questions daily\\n\"\n            \"- Revise weekly\\n\"\n            \"- Attend doubt-clearance sessions\"\n        )\n\n    elif 40 <= score < 70:\n        return (\n            \"Moderate performance.\\n\"\n            \"- Study 2 hours per day\\n\"\n            \"- Strengthen weak areas\\n\"\n            \"- Practice previous year papers\\n\"\n            \"- Revise every 3 days\"\n        )\n\n    else:\n        return (\n            \"Strong performance!\\n\"\n            \"- Maintain 1 hour revision daily\\n\"\n            \"- Solve mock tests weekly\\n\"\n            \"- Focus on accuracy and speed\\n\"\n            \"- Learn advanced topics\"\n        )\n        \nprint(\"\\n### StudyBuddy – Enter Your Details ###\\n\")\n\nuser_data = {}\n\nfor col in X.columns:\n    value = input(f\"Enter {col}: \")\n\n    if isinstance(value, str):\n        if value.strip().lower() == \"pass\":\n            value = 1\n        elif value.strip().lower() == \"fail\":\n            value = 0\n\n    try:\n        if value.strip() == \"\":\n            value = None\n        else:\n            value = float(value)\n    except:\n        pass  \n\n    user_data[col] = value\n\nuser_df = pd.DataFrame([user_data])\n\nuser_df = user_df[X.columns]\n\ntry:\n    user_pred = pipeline.predict(user_df)[0]\n    print(\"\\nPredicted Score:\", user_pred)\n    print(\"\\nStudyBuddy Recommendation:\\n\", study_plan(user_pred))\n\nexcept Exception as e:\n    print(\"\\nError during user prediction:\")\n    print(e)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Dataset loaded successfully!\n   Study Hours  Previous Exam Score  Pass/Fail\n0     4.370861            81.889703          0\n1     9.556429            72.165782          1\n2     7.587945            58.571657          0\n3     6.387926            88.827701          1\n4     2.404168            81.083870          0\nNumeric columns: ['Previous Exam Score', 'Pass/Fail']\nCategorical columns: []\nModel training completed!\nMAE: 1.787\nR² Score: 0.185\n\nTop important features (showing up to first 50):\n               feature  importance\n0  Previous Exam Score    0.611119\n1            Pass/Fail    0.388881\n\n### StudyBuddy – Enter Your Details ###\n\n"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Enter Previous Exam Score:  75\nEnter Pass/Fail:  Pass\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nPredicted Score: 6.457623684207761\n\nStudyBuddy Recommendation:\n Your performance is low.\n- Study 3–4 hours per day\n- Focus first on weak subjects\n- Solve at least 30 practice questions daily\n- Revise weekly\n- Attend doubt-clearance sessions\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "77849cf4-fc3e-496b-91bf-212265bfc557",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}